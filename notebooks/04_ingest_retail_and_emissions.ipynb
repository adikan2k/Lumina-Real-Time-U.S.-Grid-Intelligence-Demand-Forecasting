{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "04 — Ingest Retail Sales & Carbon Emissions\n",
    "=============================================\n",
    "Lumina Forecasting Hub\n",
    "\n",
    "Part A: Retail Sales (monthly)\n",
    "  - electricity/retail-sales → price, revenue, sales, customers by state & sector\n",
    "  - Feeds Dashboard Page 3: Carbon & Cost Intelligence\n",
    "\n",
    "Part B: Carbon Emissions (annual, from SEDS)\n",
    "  - seds → CO2 emissions by state, energy source, and sector\n",
    "  - Feeds Dashboard Page 3: Carbon intensity map, scatter plots\n",
    "\n",
    "Usage in Colab:\n",
    "  1. Run 01_setup_bigquery_schema.py first\n",
    "  2. Set your EIA_API_KEY and GCP_PROJECT_ID below\n",
    "  3. Run all cells"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from google.colab import auth\nauth.authenticate_user()\n\nimport requests\nimport pandas as pd\nimport numpy as np\nimport time\nfrom google.cloud import bigquery\n\n# ── Config ──────────────────────────────────────────────────────────\nEIA_API_KEY    = \"YOUR_EIA_API_KEY\"       # <-- UPDATE\nGCP_PROJECT_ID = \"YOUR_GCP_PROJECT_ID\"    # <-- UPDATE\nBQ_DATASET     = \"lumina\"\nEIA_BASE_URL   = \"https://api.eia.gov/v2\"\n\nUS_STATES = [\n    \"AL\",\"AK\",\"AZ\",\"AR\",\"CA\",\"CO\",\"CT\",\"DE\",\"FL\",\"GA\",\n    \"HI\",\"ID\",\"IL\",\"IN\",\"IA\",\"KS\",\"KY\",\"LA\",\"ME\",\"MD\",\n    \"MA\",\"MI\",\"MN\",\"MS\",\"MO\",\"MT\",\"NE\",\"NV\",\"NH\",\"NJ\",\n    \"NM\",\"NY\",\"NC\",\"ND\",\"OH\",\"OK\",\"OR\",\"PA\",\"RI\",\"SC\",\n    \"SD\",\"TN\",\"TX\",\"UT\",\"VT\",\"VA\",\"WA\",\"WV\",\"WI\",\"WY\",\"DC\",\n]\n\nSECTORS = [\"RES\", \"COM\", \"IND\", \"TRA\", \"OTH\"]  # Residential, Commercial, Industrial, Transportation, Other\n\nBACKFILL_START_MONTHLY = \"2019-01\"\nBACKFILL_START_ANNUAL  = \"2010\"\n\nclient = bigquery.Client(project=GCP_PROJECT_ID)\nprint(f\"Connected to BigQuery: {GCP_PROJECT_ID}\")\n\n# ── Retry helper for flaky EIA API ──────────────────────────────\ndef api_get_with_retry(url, params, max_retries=5):\n    \"\"\"GET request with exponential backoff retry for 5xx errors.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            resp = requests.get(url, params=params, timeout=60)\n            resp.raise_for_status()\n            return resp\n        except (requests.exceptions.HTTPError, requests.exceptions.ConnectionError, requests.exceptions.Timeout) as e:\n            if attempt < max_retries - 1:\n                wait = 2 ** attempt * 5\n                print(f\"  API error ({e}), retrying in {wait}s (attempt {attempt+1}/{max_retries})\")\n                time.sleep(wait)\n            else:\n                raise\n\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_retail_sales(sector_code, start, end=None):\n    \"\"\"\n    Fetch monthly retail electricity sales for a given sector across all states.\n    \n    Returns: revenue (million $), sales (MWh), price (cents/kWh), customers\n    \"\"\"\n    route = f\"{EIA_BASE_URL}/electricity/retail-sales/data/\"\n    \n    all_records = []\n    offset = 0\n    page_size = 5000\n    \n    while True:\n        params = {\n            \"api_key\": EIA_API_KEY,\n            \"frequency\": \"monthly\",\n            \"data[0]\": \"revenue\",\n            \"data[1]\": \"sales\",\n            \"data[2]\": \"price\",\n            \"data[3]\": \"customers\",\n            \"facets[sectorid][]\": sector_code,\n            \"sort[0][column]\": \"period\",\n            \"sort[0][direction]\": \"asc\",\n            \"offset\": offset,\n            \"length\": page_size,\n        }\n        if start:\n            params[\"start\"] = start\n        if end:\n            params[\"end\"] = end\n        \n        resp = api_get_with_retry(route, params=params)\n        body = resp.json()\n        \n        data = body.get(\"response\", {}).get(\"data\", [])\n        total = int(body.get(\"response\", {}).get(\"total\", 0))\n        \n        if not data:\n            break\n        \n        all_records.extend(data)\n        offset += page_size\n        \n        print(f\"  [Retail/{sector_code}] {len(all_records)}/{total}\", end=\"\\r\")\n        \n        if offset >= total:\n            break\n        \n        time.sleep(0.25)\n    \n    print(f\"  [Retail/{sector_code}] {len(all_records)} records fetched\")\n    return pd.DataFrame(all_records) if all_records else pd.DataFrame()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_max_period_retail():\n",
    "    query = f\"\"\"\n",
    "    SELECT FORMAT_DATE('%Y-%m', MAX(period_month)) AS max_period\n",
    "    FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_retail_sales`\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = client.query(query).to_dataframe()\n",
    "        val = result[\"max_period\"].iloc[0]\n",
    "        return val if not pd.isna(val) else BACKFILL_START_MONTHLY\n",
    "    except Exception:\n",
    "        return BACKFILL_START_MONTHLY"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "MODE = \"backfill\"  # Change to \"incremental\" after first run\n",
    "\n",
    "if MODE == \"incremental\":\n",
    "    retail_start = get_max_period_retail()\n",
    "else:\n",
    "    retail_start = BACKFILL_START_MONTHLY\n",
    "\n",
    "print(f\"=== RETAIL SALES INGESTION (from {retail_start}) ===\\n\")\n",
    "\n",
    "all_retail = []\n",
    "for sector in SECTORS:\n",
    "    df = fetch_retail_sales(sector, start=retail_start)\n",
    "    if not df.empty:\n",
    "        all_retail.append(df)\n",
    "\n",
    "if all_retail:\n",
    "    raw_retail = pd.concat(all_retail, ignore_index=True)\n",
    "    print(f\"\\nRaw retail records: {len(raw_retail):,}\")\n",
    "    \n",
    "    # ── Transform ────────────────────────────────────────────────────\n",
    "    df = raw_retail.copy()\n",
    "    \n",
    "    # Filter to US states only\n",
    "    if \"stateid\" in df.columns:\n",
    "        df = df[df[\"stateid\"].isin(US_STATES)].copy()\n",
    "    \n",
    "    # Parse period\n",
    "    df[\"period_month\"] = pd.to_datetime(df[\"period\"] + \"-01\", format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "    \n",
    "    # Rename columns\n",
    "    col_map = {\n",
    "        \"stateid\": \"state_code\",\n",
    "        \"sectorid\": \"sector_code\",\n",
    "        \"revenue\": \"revenue_musd\",\n",
    "        \"sales\": \"sales_mwh\",\n",
    "        \"price\": \"price_cents_kwh\",\n",
    "        \"customers\": \"customers\",\n",
    "    }\n",
    "    df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})\n",
    "    \n",
    "    # Type casting\n",
    "    for num_col in [\"revenue_musd\", \"sales_mwh\", \"price_cents_kwh\", \"customers\"]:\n",
    "        if num_col in df.columns:\n",
    "            df[num_col] = pd.to_numeric(df[num_col], errors=\"coerce\")\n",
    "    \n",
    "    if \"customers\" in df.columns:\n",
    "        df[\"customers\"] = df[\"customers\"].astype(\"Int64\")  # Nullable integer\n",
    "    \n",
    "    # Final columns\n",
    "    final_cols = [\"period_month\", \"state_code\", \"sector_code\", \"revenue_musd\", \"sales_mwh\", \"price_cents_kwh\", \"customers\"]\n",
    "    for col in final_cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "    \n",
    "    result_retail = df[final_cols].dropna(subset=[\"period_month\"]).copy()\n",
    "    result_retail = result_retail.sort_values([\"period_month\", \"state_code\", \"sector_code\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Cleaned retail records: {len(result_retail):,}\")\n",
    "    print(f\"Date range: {result_retail['period_month'].min()} → {result_retail['period_month'].max()}\")\n",
    "    \n",
    "    # ── Load to BigQuery ─────────────────────────────────────────────\n",
    "    table_ref = f\"{GCP_PROJECT_ID}.{BQ_DATASET}.fact_retail_sales\"\n",
    "    write_mode = \"WRITE_TRUNCATE\" if MODE == \"backfill\" else \"WRITE_APPEND\"\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=write_mode)\n",
    "    \n",
    "    job = client.load_table_from_dataframe(result_retail, table_ref, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"Loaded {len(result_retail):,} rows to fact_retail_sales\")\n",
    "else:\n",
    "    print(\"No retail sales data fetched.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def fetch_seds_co2(start=\"2010\"):\n    \"\"\"\n    Fetch annual CO2 emissions from the SEDS dataset.\n    \n    SEDS series codes for CO2:\n      - TETCB = Total energy CO2 emissions (million metric tons)\n      - Various msn codes for breakdowns by source/sector\n    \n    We use the seds route with appropriate facets.\n    \"\"\"\n    route = f\"{EIA_BASE_URL}/seds/data/\"\n    \n    # SEDS MSN codes for CO2 emissions (million metric tons CO2)\n    # Pattern: XX TC B  where XX = source, TC = total consumption, B = billion Btu basis\n    # CO2 codes end in 'CD' for carbon dioxide\n    co2_msn_patterns = [\n        \"TETCB\",  # Total energy-related CO2 emissions\n        \"CLTCB\",  # Coal CO2\n        \"NNTCB\",  # Natural gas CO2\n        \"PATCB\",  # Petroleum CO2\n    ]\n    \n    all_records = []\n    offset = 0\n    page_size = 5000\n    \n    while True:\n        params = {\n            \"api_key\": EIA_API_KEY,\n            \"frequency\": \"annual\",\n            \"data[0]\": \"value\",\n            \"sort[0][column]\": \"period\",\n            \"sort[0][direction]\": \"asc\",\n            \"offset\": offset,\n            \"length\": page_size,\n            \"start\": start,\n        }\n        \n        # Filter for CO2-related series\n        for i, msn in enumerate(co2_msn_patterns):\n            params[f\"facets[seriesId][]\"] = msn  # Note: API may need different handling\n        \n        resp = api_get_with_retry(route, params=params)\n        body = resp.json()\n        \n        data = body.get(\"response\", {}).get(\"data\", [])\n        total = int(body.get(\"response\", {}).get(\"total\", 0))\n        \n        if not data:\n            break\n        \n        all_records.extend(data)\n        offset += page_size\n        \n        print(f\"  [SEDS/CO2] {len(all_records)}/{total}\", end=\"\\r\")\n        \n        if offset >= total:\n            break\n        \n        time.sleep(0.25)\n    \n    print(f\"  [SEDS/CO2] {len(all_records)} records fetched\")\n    return pd.DataFrame(all_records) if all_records else pd.DataFrame()\n\n\ndef fetch_seds_co2_by_source(start=\"2010\"):\n    \"\"\"\n    Alternative approach: Fetch CO2 emissions using the co2-emissions route\n    which is more structured for our needs.\n    \n    Route: /co2-emissions/co2-emissions-aggregates/data/\n    Facets: sectorId, fuelId, stateId\n    \"\"\"\n    route = f\"{EIA_BASE_URL}/co2-emissions/co2-emissions-aggregates/data/\"\n    \n    all_records = []\n    offset = 0\n    page_size = 5000\n    \n    while True:\n        params = {\n            \"api_key\": EIA_API_KEY,\n            \"frequency\": \"annual\",\n            \"data[0]\": \"value\",\n            \"sort[0][column]\": \"period\",\n            \"sort[0][direction]\": \"asc\",\n            \"offset\": offset,\n            \"length\": page_size,\n            \"start\": start,\n        }\n        \n        resp = requests.get(route, params=params)\n        \n        # This endpoint may be deprecated — fall back gracefully\n        if resp.status_code != 200:\n            print(f\"  CO2 aggregates endpoint returned {resp.status_code}, trying SEDS route...\")\n            return pd.DataFrame()\n        \n        body = resp.json()\n        data = body.get(\"response\", {}).get(\"data\", [])\n        total = int(body.get(\"response\", {}).get(\"total\", 0))\n        \n        if not data:\n            break\n        \n        all_records.extend(data)\n        offset += page_size\n        \n        print(f\"  [CO2 Aggregates] {len(all_records)}/{total}\", end=\"\\r\")\n        \n        if offset >= total:\n            break\n        \n        time.sleep(0.25)\n    \n    print(f\"  [CO2 Aggregates] {len(all_records)} records fetched\")\n    return pd.DataFrame(all_records) if all_records else pd.DataFrame()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(f\"\\n=== CARBON EMISSIONS INGESTION (from {BACKFILL_START_ANNUAL}) ===\\n\")\n",
    "\n",
    "# Try the dedicated CO2 endpoint first, fall back to SEDS\n",
    "raw_co2 = fetch_seds_co2_by_source(start=BACKFILL_START_ANNUAL)\n",
    "\n",
    "if raw_co2.empty:\n",
    "    print(\"Falling back to SEDS route for CO2 data...\")\n",
    "    raw_co2 = fetch_seds_co2(start=BACKFILL_START_ANNUAL)\n",
    "\n",
    "if not raw_co2.empty:\n",
    "    print(f\"\\nRaw CO2 records: {len(raw_co2):,}\")\n",
    "    print(f\"Columns: {list(raw_co2.columns)}\")\n",
    "    \n",
    "    df = raw_co2.copy()\n",
    "    \n",
    "    # The CO2 aggregates endpoint returns: period, stateId, sectorId, fuelId, value\n",
    "    # The SEDS endpoint returns: period, stateId, seriesId, value\n",
    "    \n",
    "    # Normalize column names\n",
    "    col_map = {\n",
    "        \"stateId\": \"state_code\",\n",
    "        \"stateid\": \"state_code\",\n",
    "        \"sectorId\": \"sector_code\",\n",
    "        \"sectorid\": \"sector_code\",\n",
    "        \"fuelId\": \"source_code\",\n",
    "        \"fuelid\": \"source_code\",\n",
    "        \"seriesId\": \"source_code\",\n",
    "        \"value\": \"emissions_mmt\",\n",
    "    }\n",
    "    df.columns = [col_map.get(c, c) for c in df.columns]\n",
    "    \n",
    "    # Filter to US states\n",
    "    if \"state_code\" in df.columns:\n",
    "        df = df[df[\"state_code\"].isin(US_STATES)].copy()\n",
    "    \n",
    "    # Parse period as integer year\n",
    "    df[\"period_year\"] = pd.to_numeric(df[\"period\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"emissions_mmt\"] = pd.to_numeric(df.get(\"emissions_mmt\", pd.Series(dtype=float)), errors=\"coerce\")\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    for col in [\"state_code\", \"source_code\", \"sector_code\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"ALL\"\n",
    "    \n",
    "    final_cols = [\"period_year\", \"state_code\", \"source_code\", \"sector_code\", \"emissions_mmt\"]\n",
    "    result_co2 = df[final_cols].dropna(subset=[\"period_year\"]).copy()\n",
    "    result_co2 = result_co2.sort_values([\"period_year\", \"state_code\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Cleaned CO2 records: {len(result_co2):,}\")\n",
    "    print(f\"Year range: {result_co2['period_year'].min()} → {result_co2['period_year'].max()}\")\n",
    "    \n",
    "    # ── Load to BigQuery ─────────────────────────────────────────────\n",
    "    table_ref = f\"{GCP_PROJECT_ID}.{BQ_DATASET}.fact_carbon_emissions\"\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\")\n",
    "    \n",
    "    job = client.load_table_from_dataframe(result_co2, table_ref, job_config=job_config)\n",
    "    job.result()\n",
    "    print(f\"Loaded {len(result_co2):,} rows to fact_carbon_emissions\")\n",
    "else:\n",
    "    print(\"No CO2 data fetched. You may need to check available SEDS series codes.\")\n",
    "    print(\"Try exploring: https://api.eia.gov/v2/seds/?api_key=YOUR_KEY\")\n",
    "    print(\"Or use the SEDS bulk download: https://www.eia.gov/opendata/bulk/SEDS.zip\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"\\n=== RETAIL SALES QUALITY CHECK ===\")\n",
    "retail_quality = f\"\"\"\n",
    "SELECT\n",
    "    sector_code,\n",
    "    COUNT(*) AS rows,\n",
    "    COUNT(DISTINCT state_code) AS states,\n",
    "    MIN(period_month) AS earliest,\n",
    "    MAX(period_month) AS latest,\n",
    "    ROUND(AVG(price_cents_kwh), 2) AS avg_price_cents,\n",
    "    ROUND(SUM(sales_mwh) / 1e9, 2) AS total_sales_twh,\n",
    "    ROUND(SUM(revenue_musd) / 1e3, 2) AS total_revenue_busd\n",
    "FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_retail_sales`\n",
    "GROUP BY sector_code\n",
    "ORDER BY total_sales_twh DESC\n",
    "\"\"\"\n",
    "try:\n",
    "    df_rq = client.query(retail_quality).to_dataframe()\n",
    "    print(df_rq.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"Retail quality check error: {e}\")\n",
    "\n",
    "print(\"\\n=== CARBON EMISSIONS QUALITY CHECK ===\")\n",
    "co2_quality = f\"\"\"\n",
    "SELECT\n",
    "    period_year,\n",
    "    COUNT(DISTINCT state_code) AS states,\n",
    "    ROUND(SUM(emissions_mmt), 1) AS total_mmt,\n",
    "    COUNT(*) AS rows\n",
    "FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_carbon_emissions`\n",
    "GROUP BY period_year\n",
    "ORDER BY period_year DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "try:\n",
    "    df_cq = client.query(co2_quality).to_dataframe()\n",
    "    print(df_cq.to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(f\"CO2 quality check error: {e}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scatter_query = f\"\"\"\n",
    "WITH latest_price AS (\n",
    "    SELECT\n",
    "        state_code,\n",
    "        AVG(price_cents_kwh) AS avg_price\n",
    "    FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_retail_sales`\n",
    "    WHERE sector_code = 'RES'\n",
    "        AND period_month >= DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH)\n",
    "    GROUP BY state_code\n",
    "),\n",
    "latest_co2 AS (\n",
    "    SELECT\n",
    "        state_code,\n",
    "        SUM(emissions_mmt) AS total_co2\n",
    "    FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_carbon_emissions`\n",
    "    WHERE period_year = (\n",
    "        SELECT MAX(period_year) FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_carbon_emissions`\n",
    "    )\n",
    "    GROUP BY state_code\n",
    "),\n",
    "latest_gen AS (\n",
    "    SELECT\n",
    "        state_code,\n",
    "        SUM(generation_mwh) / 1e3 AS total_gwh\n",
    "    FROM `{GCP_PROJECT_ID}.{BQ_DATASET}.fact_monthly_generation`\n",
    "    WHERE period_month >= DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH)\n",
    "        AND sector_code = '99'\n",
    "    GROUP BY state_code\n",
    ")\n",
    "SELECT\n",
    "    p.state_code,\n",
    "    g.state_name,\n",
    "    g.population,\n",
    "    p.avg_price,\n",
    "    SAFE_DIVIDE(c.total_co2 * 1e6, gen.total_gwh) AS co2_intensity_tons_gwh\n",
    "FROM latest_price p\n",
    "JOIN `{GCP_PROJECT_ID}.{BQ_DATASET}.dim_geography` g ON p.state_code = g.state_code\n",
    "LEFT JOIN latest_co2 c ON p.state_code = c.state_code\n",
    "LEFT JOIN latest_gen gen ON p.state_code = gen.state_code\n",
    "WHERE gen.total_gwh > 0\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    df_scatter = client.query(scatter_query).to_dataframe()\n",
    "    \n",
    "    if not df_scatter.empty:\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        sizes = df_scatter[\"population\"] / 1e5  # Scale for visibility\n",
    "        scatter = ax.scatter(\n",
    "            df_scatter[\"co2_intensity_tons_gwh\"],\n",
    "            df_scatter[\"avg_price\"],\n",
    "            s=sizes,\n",
    "            alpha=0.6,\n",
    "            c=df_scatter[\"co2_intensity_tons_gwh\"],\n",
    "            cmap=\"RdYlGn_r\",\n",
    "            edgecolors=\"white\",\n",
    "            linewidth=0.5,\n",
    "        )\n",
    "        \n",
    "        # Label top states\n",
    "        for _, row in df_scatter.nlargest(10, \"population\").iterrows():\n",
    "            ax.annotate(\n",
    "                row[\"state_code\"],\n",
    "                (row[\"co2_intensity_tons_gwh\"], row[\"avg_price\"]),\n",
    "                fontsize=8, ha=\"center\", va=\"bottom\",\n",
    "            )\n",
    "        \n",
    "        ax.set_xlabel(\"CO2 Intensity (tons/GWh)\", fontsize=12)\n",
    "        ax.set_ylabel(\"Avg Residential Price (¢/kWh)\", fontsize=12)\n",
    "        ax.set_title(\"State-Level: Carbon Intensity vs. Electricity Price\\n(bubble size = population)\", fontsize=14)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "        plt.colorbar(scatter, label=\"CO2 Intensity\", shrink=0.8)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data for scatter plot.\")\n",
    "except Exception as e:\n",
    "    print(f\"Scatter plot error: {e}\")\n",
    "    print(\"This visualization requires all 3 fact tables to be populated.\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}